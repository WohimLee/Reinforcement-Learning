&emsp;
# Prerequisite

# 1 Softmax
softmax 将多个值映射到 (0,1) 内，可以看成概率

$$softmax(\pmb{X}_{ij}) = \frac{exp({\pmb{X}_{ij}})}{\sum_k exp(\pmb{X}_{ik})}$$

```py
class Bandit:
    ...
    def act(self):
        # 改成了 softmax
        exp_est = np.exp(self.q_estimation)
        self.action_prob = exp_est / np.sum(exp_est)
        return np.random.choice(self.indices, p=self.action_prob)
    ...
```

&emsp;
# 2 更新公式

$$H_{t+1}(a) = H_t(a) + \alpha(R_t - \bar{R}_t)(\mathbb{I}_{a=A_t} - softmax)$$
- $\mathbb{I}_{a=A_t}$: 如果 $a=x$ 就取 1，否则取 0，可以用 one hot 编码

```py
class Bandit:
    ...
    def step(self, action):
        self.time += 1
        self.action_count[action] += 1
        
        reward = np.random.randn() + self.q_true[action]
        self.average_reward += (reward - self.average_reward) / self.time
        
        one_hot = np.zeros(self.k)
        one_hot[action] = 1
        if self.gradient_baseline:
            baseline = self.average_reward
        else:
            baseline = 0
        self.q_estimation += self.step_size * (reward - baseline) * (one_hot - self.action_prob)

        return reward
```






